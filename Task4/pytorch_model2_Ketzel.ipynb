{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "import torch.utils.data as datatorch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import torch.backends.cudnn as cudnn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch.nn.functional as F\n",
    "from training_split import split_training\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_triplets = np.loadtxt('train_triplets.txt', dtype= 'str')\n",
    "#train_triplets, val_triplets, _unused = split_training()\n",
    "test_triplets = np.loadtxt('test_triplets.txt', dtype= 'str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59515, 3)\n",
      "(53563, 3) (5952, 3)\n",
      "2976\n",
      "(5952,)\n"
     ]
    }
   ],
   "source": [
    "print(train_triplets.shape)\n",
    "train_triplets, val_triplets = train_test_split(train_triplets, test_size = 0.1)\n",
    "print(train_triplets.shape, val_triplets.shape)\n",
    "half_index = np.int64((val_triplets.shape[0]-val_triplets.shape[0]%2)/2)\n",
    "print(half_index)\n",
    "val_labels = np.int64(np.ones((val_triplets.shape[0],)))\n",
    "print(val_labels.shape)\n",
    "val_triplets[half_index:, 1], val_triplets[half_index:, 2] = val_triplets[half_index:, 2], val_triplets[half_index:, 1].copy()\n",
    "val_labels[half_index:] = np.int64(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59544, 3)\n"
     ]
    }
   ],
   "source": [
    "print(test_triplets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(train_triplets.shape)\n",
    "#print()\n",
    "train_triplets , val_triplets = train_test_split(train_triplets, test_size = 0.1)\n",
    "print(train_triplets.shape, val_triplets.shape)\n",
    "half_index = np.int64((val_triplets.shape[0]-val_triplets.shape[0]%2)/2)\n",
    "print(half_index)\n",
    "val_labels = np.int64(np.ones((val_triplets.shape[0],)))\n",
    "print(val_labels.shape)\n",
    "val_triplets[half_index:, 0], val_triplets[half_index:, 1] = val_triplets[half_index:, 1], val_triplets[half_index:, 0].copy()\n",
    "val_labels[half_index:] = np.int64(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'food/food'\n",
    "train_files = os.listdir(train_dir)\n",
    "test_files = os.listdir(train_dir)\n",
    "\n",
    "\n",
    "class ImageTriplesSet(Dataset):\n",
    "    def __init__(self , file_array, dir, mode='train', transform = None,labels =None):\n",
    "        self.triple_list = list(map(tuple, file_array))\n",
    "        self.mode = mode\n",
    "        self.labels = labels\n",
    "        self.dir = dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.triple_list)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img1 = Image.open(os.path.join(self.dir, self.triple_list[idx][0] + '.jpg'))\n",
    "        img2 = Image.open(os.path.join(self.dir, self.triple_list[idx][1] + '.jpg'))\n",
    "        img3 = Image.open(os.path.join(self.dir, self.triple_list[idx][2] + '.jpg'))\n",
    "        \n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img1 = self.transform(img1).numpy()\n",
    "            img2 = self.transform(img2).numpy()\n",
    "            img3 = self.transform(img3).numpy()\n",
    "        if self.labels is None:\n",
    "            return img1, img2, img3\n",
    "        else:\n",
    "            return img1, img2, img3, self.labels[idx]\n",
    "            \n",
    "        #concat_img = cv2.hconcat([img1, img2, img3]).astype('float32')\n",
    "        #if self.mode == 'train':\n",
    "            #label = self.labels[idx]\n",
    "            #return concat_img , label\n",
    "            \n",
    "        #else:\n",
    "            #return concat_img, int(self.triple_list[idx][:-4])\n",
    "        \n",
    "#data_transform = transforms.Compose([\n",
    "  #  transforms.Resize(350,240),\n",
    "  #  transforms.CenterCrop(240),\n",
    "  #  transforms.ToTensor()\n",
    "#])\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "        transforms.Resize(330),\n",
    "        transforms.CenterCrop(300),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "train_dataset = ImageTriplesSet(train_triplets, train_dir, transform = data_transform, labels = None)\n",
    "val_dataset = ImageTriplesSet(val_triplets, train_dir, transform= data_transform, labels = None)\n",
    "test_dataset = ImageTriplesSet(test_triplets, train_dir, mode=\"test\" ,transform = data_transform,labels = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(5,5)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d((2,2)),\n",
    "            torch.nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d((2,2)),\n",
    "            torch.nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3,3)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d((2,2)),\n",
    "            torch.nn.Conv2d(in_channels=256, out_channels=128, kernel_size=(2,2))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = torch.hub.load('pytorch/vision', 'resnet34', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:01.466628\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.5\n",
    "batch_size = 8\n",
    "epochs = 3\n",
    "logstep = int(10000 // batch_size)\n",
    "\n",
    "train_loader = datatorch.DataLoader(dataset=train_dataset, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(5,5)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d((2,2)),\n",
    "            torch.nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d((2,2)),\n",
    "            torch.nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3,3)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d((2,2)),\n",
    "            torch.nn.Conv2d(in_channels=256, out_channels=128, kernel_size=(2,2)),\n",
    ")\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "criterion = nn.TripletMarginLoss(margin=1.0, p=2)\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate,momentum=0.9,weight_decay=1e-5,nesterov=True)\n",
    "\n",
    "training_loss_vec = []\n",
    "training_accuracy_vec = []\n",
    "val_f1_score = []\n",
    "\n",
    "start = time.time()\n",
    "# loop over epochs\n",
    "model.train()\n",
    "for e in range(epochs):\n",
    "    training_loss = 0.\n",
    "    training_accuracy = 0.\n",
    "    for idx, (data1, data2, data3) in enumerate(train_loader):\n",
    "        data1, data2, data3 = data1.cuda(), data2.cuda(), data3.cuda()\n",
    "        embedded_a, embedded_p, embedded_n = model(data1), model(data2), model(data3)\n",
    "        loss = criterion(embedded_a, embedded_p, embedded_n)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        training_loss += loss.item()\n",
    "        break\n",
    "        if (idx+1) % logstep == 0: \n",
    "            training_loss_vec.append(training_loss/logstep)\n",
    "            print('[%d, %5d] training loss: %.5f' %\n",
    "                  (e + 1, idx + 1, training_loss/logstep))\n",
    "            training_loss, training_accuracy = 0.,0.\n",
    "            break \n",
    "end = time.time()\n",
    "print(str(datetime.timedelta(seconds= end - start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(logstep*np.arange(1,1+len(training_loss_vec)),np.array(training_loss_vec))\n",
    "plt.ylabel(\"loss criterion\")\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 128, 34, 34])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size 64 3 5 5, expected input[8, 128, 34, 34] to have 3 channels, but got 128 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-a29c694053c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;31m#target = torch.FloatTensor(dist_a.size()).fill_(1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mdist_n\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mdist_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeat_a\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeat_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdist_n\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mconv2d_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    338\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    339\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[1;32m--> 340\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size 64 3 5 5, expected input[8, 128, 34, 34] to have 3 channels, but got 128 channels instead"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.5\n",
    "epochs = 3\n",
    "train_loader = datatorch.DataLoader(dataset=train_dataset, shuffle=False, batch_size=8)\n",
    "\n",
    "model2 = torch.nn.Sequential(nn.Flatten(),\n",
    "            nn.Linear(147968,2048),\n",
    "            )\n",
    "   \n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model2 =model2.to(device)\n",
    "#create optimizer\n",
    "criterion2 = nn.CrossEntropyLoss()\n",
    "optimizer2 = torch.optim.SGD(model2.parameters(),lr=learning_rate,momentum=0.9,weight_decay=1e-5,nesterov=True)\n",
    "\n",
    "training_loss_vec = []\n",
    "training_accuracy_vec = []\n",
    "val_loss_vec = []\n",
    "val_f1_score = []\n",
    "    \n",
    "\n",
    "start = time.time()\n",
    "model.eval()\n",
    "for e in range(epochs):\n",
    "    training_loss = 0.\n",
    "    training_accuracy = 0.\n",
    "    \n",
    "    model2.train()\n",
    "    for idx, (data1, data2, data3) in enumerate(train_loader):\n",
    "        data1, data2, data3 = data1.cuda(), data2.cuda(), data3.cuda()\n",
    "        embedded_a, embedded_p, embedded_n = model(data1), model(data2), model(data3)\n",
    "        \n",
    "        print(embedded_a.size())\n",
    "        \n",
    "        #feat_a = F.pairwise_distance(embedded_a, embedded_n, 2).cuda()\n",
    "        #feat_b = F.pairwise_distance(embedded_a, embedded_p, 2).cuda()\n",
    "        feat_a = embedded_n.cuda()\n",
    "        feat_b = embedded_p.cuda()\n",
    "        \n",
    "        #target = torch.FloatTensor(dist_a.size()).fill_(1)\n",
    "        dist_n , dist_p = model2(feat_a), model(feat_b)\n",
    "        print(dist_n.size())\n",
    "        break\n",
    "        print(y_pred.size())\n",
    "        loss = criterion2(y_pred,target) \n",
    "        # call optimizer.zero_grad()\n",
    "        optimizer2.zero_grad()\n",
    "        # run backward method\n",
    "        loss.backward()\n",
    "        # run optimizer step\n",
    "        optimizer2.step()\n",
    "        training_loss += loss.item()\n",
    "        y_pred_idx = torch.max(y_pred.detach().cpu(),dim=1)[1]\n",
    "        training_accuracy += torch.mean((y_pred_idx == target.cpu()).float()).item()\n",
    "        break\n",
    "        if (n+1) % logstep == 0: \n",
    "            training_loss_vec.append(training_loss/logstep)\n",
    "            training_accuracy_vec.append(training_accuracy/logstep)\n",
    "            print('training loss: ', training_loss/logstep,'traing_acc: ',training_accuracy/logstep)\n",
    "            training_loss, training_accuracy = 0.,0.\n",
    "            \n",
    "    val_labels_pred = []\n",
    "    model2.eval()\n",
    "    for idx, (data1, data2, data3) in enumerate(val_loader):\n",
    "        data1, data2, data3 = data1.cuda(), data2.cuda(), data3.cuda()\n",
    "        embedded_a, embedded_p, embedded_n = model(data1), model(data2), model(data3)\n",
    "\n",
    "        dist_a = torch.dist(embedded_a, embedded_n, 2).cuda()\n",
    "        dist_b = torch.dist(embedded_a, embedded_p, 2).cuda()\n",
    "        feat = torch.cat((dist_a, dist_b), 0)\n",
    "        output = model2(feat)\n",
    "        pred = torch.argmax(output, dim=1)\n",
    "        val_labels_pred += pred\n",
    "\n",
    "    f1 = f1_score(val_labels_pred, val_labels)\n",
    "    acc = accuracy_score(val_labels_pred, val_labels)\n",
    "    val_f1_score.append(f1)\n",
    "    print('Epoch :',e,' Current Validation F1 Score: ', f1, 'Current Val Acc:', acc)\n",
    "    \n",
    "    \n",
    "\n",
    "end = time.time()\n",
    "print(str(datetime.timedelta(seconds= end - start)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(val_labels_pred,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = datatorch.DataLoader(dataset=test_dataset, shuffle = False, batch_size= 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_triplets_pred = []\n",
    "model.eval()\n",
    "model2.eval()\n",
    "for idx, (data1, data2, data3) in enumerate(test_loader):\n",
    "    data1, data2, data3 = data1.cuda(), data2.cuda(), data3.cuda()\n",
    "    embedded_a, embedded_p, embedded_n = model(data1), model(data2), model(data3)\n",
    "    dist_a = torch.dist(embedded_a, embedded_n, 2)\n",
    "    dist_b = torch.dist(embedded_a, embedded_p, 2)\n",
    "    feat = torch.cat((dist_a, dist_b), 0).cuda()\n",
    "    output = model2(feat)\n",
    "    pred = torch.argmax(output, dim=1)\n",
    "    test_triplets_pred += pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_triplets_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submission2_Ketzel.txt', 'w') as f:\n",
    "    for item in test_triplets_pred:\n",
    "        f.write(str(item) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
