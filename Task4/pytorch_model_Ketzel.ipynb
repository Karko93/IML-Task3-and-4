{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "import torch.utils.data as datatorch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import torch.backends.cudnn as cudnn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_triplets = np.loadtxt('train_triplets.txt', dtype= 'str')\n",
    "test_triplets = np.loadtxt('test_triplets.txt', dtype= 'str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59544, 3)\n"
     ]
    }
   ],
   "source": [
    "print(test_triplets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59515, 3)\n",
      "(53563, 3) (5952, 3)\n",
      "2976\n",
      "(5952,)\n"
     ]
    }
   ],
   "source": [
    "print(train_triplets.shape)\n",
    "#print()\n",
    "train_triplets , val_triplets = train_test_split(train_triplets, test_size = 0.1)\n",
    "print(train_triplets.shape, val_triplets.shape)\n",
    "half_index = np.int64((val_triplets.shape[0]-val_triplets.shape[0]%2)/2)\n",
    "print(half_index)\n",
    "val_labels = np.int64(np.ones((val_triplets.shape[0],)))\n",
    "print(val_labels.shape)\n",
    "val_triplets[half_index:, 1], val_triplets[half_index:, 2] = val_triplets[half_index:, 2], val_triplets[half_index:, 1].copy()\n",
    "val_labels[half_index:] = np.int64(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'food/food'\n",
    "train_files = os.listdir(train_dir)\n",
    "test_files = os.listdir(train_dir)\n",
    "\n",
    "\n",
    "class ImageTriplesSet(Dataset):\n",
    "    def __init__(self , file_array, dir, mode='train', transform = None,labels =None):\n",
    "        self.triple_list = list(map(tuple, file_array))\n",
    "        self.mode = mode\n",
    "        self.labels = labels\n",
    "        self.dir = dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.triple_list)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img1 = Image.open(os.path.join(self.dir, self.triple_list[idx][0] + '.jpg'))\n",
    "        img2 = Image.open(os.path.join(self.dir, self.triple_list[idx][1] + '.jpg'))\n",
    "        img3 = Image.open(os.path.join(self.dir, self.triple_list[idx][2] + '.jpg'))\n",
    "        \n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img1 = self.transform(img1).numpy()\n",
    "            img2 = self.transform(img2).numpy()\n",
    "            img3 = self.transform(img3).numpy()\n",
    "        if self.labels is None:\n",
    "            return img1, img2, img3\n",
    "        else:\n",
    "            return img1, img2, img3, self.labels[idx]\n",
    "            \n",
    "        #concat_img = cv2.hconcat([img1, img2, img3]).astype('float32')\n",
    "        #if self.mode == 'train':\n",
    "            #label = self.labels[idx]\n",
    "            #return concat_img , label\n",
    "            \n",
    "        #else:\n",
    "            #return concat_img, int(self.triple_list[idx][:-4])\n",
    "        \n",
    "#data_transform = transforms.Compose([\n",
    "  #  transforms.Resize(350,240),\n",
    "  #  transforms.CenterCrop(240),\n",
    "  #  transforms.ToTensor()\n",
    "#])\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "        transforms.Resize((224,244)),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "train_dataset = ImageTriplesSet(train_triplets, train_dir, transform = data_transform, labels = None)\n",
    "val_dataset = ImageTriplesSet(val_triplets, train_dir, transform= data_transform, labels = None)\n",
    "test_dataset = ImageTriplesSet(test_triplets, train_dir, mode=\"test\" ,transform = data_transform,labels = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\user/.cache\\torch\\hub\\pytorch_vision_master\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision', 'resnet34', pretrained=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3,3)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d((2,2)),\n",
    "            torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d((2,2)),\n",
    "            torch.nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d((2,2)),\n",
    "            torch.nn.Conv2d(in_channels=128, out_channels=128, kernel_size=(3,3)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d((2,2)),\n",
    "            nn.Flatten(),\n",
    "            torch.nn.Linear(32768, 2048),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss:  0.1503482230246067 \n",
      " training accuracy:  0.5542\n",
      "training loss:  0.10152836930453778 \n",
      " training accuracy:  0.5479\n",
      "training loss:  0.08855695036351681 \n",
      " training accuracy:  0.5429\n",
      "training loss:  0.08246005915403366 \n",
      " training accuracy:  0.5499\n",
      "training loss:  0.07232446353435516 \n",
      " training accuracy:  0.5652\n",
      "Epoch : 0  Current Validation F1 Score:  0.5735368103303706 Current Val Acc: 0.5727486559139785\n",
      "training loss:  0.06065049070417881 \n",
      " training accuracy:  0.5912\n",
      "training loss:  0.05582641283869744 \n",
      " training accuracy:  0.5924\n",
      "training loss:  0.049184988567233086 \n",
      " training accuracy:  0.6073\n",
      "training loss:  0.043950296711921695 \n",
      " training accuracy:  0.6206\n",
      "training loss:  0.03887475598007441 \n",
      " training accuracy:  0.6398\n",
      "Epoch : 1  Current Validation F1 Score:  0.6554031448645031 Current Val Acc: 0.6538978494623656\n",
      "training loss:  0.03128903599530458 \n",
      " training accuracy:  0.6845\n",
      "training loss:  0.028373077622056007 \n",
      " training accuracy:  0.6945\n",
      "training loss:  0.026386183081567288 \n",
      " training accuracy:  0.7079\n",
      "training loss:  0.024393189717829226 \n",
      " training accuracy:  0.7225\n",
      "training loss:  0.0223384649887681 \n",
      " training accuracy:  0.7267\n",
      "Epoch : 2  Current Validation F1 Score:  0.7381311860426103 Current Val Acc: 0.7377352150537635\n",
      "training loss:  0.017928162740170957 \n",
      " training accuracy:  0.7787\n",
      "training loss:  0.01753132777363062 \n",
      " training accuracy:  0.7797\n",
      "training loss:  0.01655710601583123 \n",
      " training accuracy:  0.7882\n",
      "training loss:  0.015707159756869076 \n",
      " training accuracy:  0.8014\n",
      "training loss:  0.015321890234202147 \n",
      " training accuracy:  0.7945\n",
      "Epoch : 3  Current Validation F1 Score:  0.8033670033670034 Current Val Acc: 0.803763440860215\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "batch_size = 16\n",
    "epochs = 4\n",
    "logstep = int(10000 // batch_size)\n",
    "margin = 0.01\n",
    "\n",
    "train_loader = datatorch.DataLoader(dataset=train_dataset, \n",
    "                         shuffle=True, \n",
    "                         batch_size=batch_size)\n",
    "\n",
    "val_loader = datatorch.DataLoader(dataset=val_dataset, shuffle = False, batch_size= batch_size)\n",
    "\n",
    "#test_loader = datatorch.DataLoader(dataset=test_dataset, shuffle = False, batch_size= batch_size)\n",
    "\n",
    "\n",
    "\n",
    "#model.fc = nn.Sequential(nn.Linear(model.fc.in_features,512),\n",
    "                                  #nn.ReLU(),\n",
    "                                  #nn.Dropout(),\n",
    "                                  #nn.Linear(512, 2))\n",
    "            \n",
    "#model.fc = nn.Sequential(nn.Linear(model.fc.in_features,1024),\n",
    "                                  #nn.ReLU(),\n",
    "                                  #nn.Linear(1024, 2048))\n",
    "        \n",
    "model.fc = nn.Sequential(nn.Linear(model.fc.in_features,512),\n",
    "                                  #nn.ReLU(),\n",
    "                                  nn.Linear(512, 2048))      \n",
    "        \n",
    "\n",
    "\n",
    "#net = TripletNet(resnet101())\n",
    "           \n",
    "            \n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cuda:0\")\n",
    "model =model.to(device)\n",
    "#net = torch.nn.DataParallel(net).cuda()\n",
    "#cudnn.benchmark = True\n",
    " #create optimizer\n",
    "criterion = nn.TripletMarginLoss(margin=margin, p=2)\n",
    "#criterion = nn.MarginRankingLoss(margin = 0.01)\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate,momentum=0.9,weight_decay=1e-5,nesterov=True)\n",
    "\n",
    "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode='min',factor=0.1,patience=10,verbose=True)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "#scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[500,1000,1500], gamma=0.5)\n",
    "\n",
    "training_loss_vec = []\n",
    "training_accuracy_vec = []\n",
    "val_loss_vec = []\n",
    "val_f1_score = []\n",
    "    \n",
    "#criterion = torch.nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "#scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[500,1000,1500], gamma=0.5)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "# loop over epochs\n",
    "\n",
    "for e in range(epochs):\n",
    "    training_loss = 0.\n",
    "    training_accuracy = 0.\n",
    "    \n",
    "    model.train()\n",
    "    for idx, (data1, data2, data3) in enumerate(train_loader):\n",
    "    #for idx, (img,label) in enumerate(train_loader):\n",
    "        data1, data2, data3 = data1.cuda(), data2.cuda(), data3.cuda()\n",
    "        #img, label = img.cuda(), label.cuda()\n",
    "        #embedded_a, embedded_p, embedded_n = net(data1, data2, data3)\n",
    "        embedded_a, embedded_p, embedded_n = model(data1), model(data2), model(data3)\n",
    "        \n",
    "        \n",
    "        dist_a = F.pairwise_distance(embedded_a, embedded_n, 2)\n",
    "        dist_b = F.pairwise_distance(embedded_a, embedded_p, 2)\n",
    "        \n",
    "        # compute predictions using model\n",
    "        #y_pred =  model(img)\n",
    "        # compute loss\n",
    "        #target = torch.FloatTensor(dist_a.size()).fill_(1)\n",
    "        #target = target.cuda()\n",
    "        #rank_loss = criterion(dist_a,dist_b,target)\n",
    "        loss_embedd = embedded_a.norm(2) + embedded_n.norm(2) + embedded_p.norm(2)\n",
    "        #loss = rank_loss# + 0.001*loss_embedd\n",
    "        loss = criterion(embedded_a, embedded_p, embedded_n)+ 0.001*loss_embedd #tripletmarginloss\n",
    "        #loss = criterion(y_pred,label) \n",
    "        # call optimizer.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        # run backward method\n",
    "        loss.backward()\n",
    "        # run optimizer step\n",
    "        optimizer.step()\n",
    "        #scheduler.step()  ######\n",
    "        # logging (optional)\n",
    "        \n",
    "        training_loss += loss.item()\n",
    "        pred = (dist_a - dist_b).cpu().data\n",
    "        training_accuracy  += torch.mean(((pred >0)*1).float()).item()\n",
    "        \n",
    "        #y_pred_idx = torch.max(y_pred.detach().cpu(),dim=1)[1]\n",
    "        #training_accuracy += torch.mean((y_pred_idx == label.cpu()).float()).item()\n",
    "        \n",
    "        if (idx+1) % logstep == 0: \n",
    "            training_loss_vec.append(training_loss/logstep)\n",
    "            training_accuracy_vec.append(training_accuracy/logstep)\n",
    "            print('training loss: ', training_loss/logstep, '\\n', 'training accuracy: ', training_accuracy/logstep)\n",
    "            training_loss, training_accuracy = 0.,0.\n",
    "            \n",
    "    val_labels_pred = []\n",
    "    model.eval()\n",
    "    for idx, (data1, data2, data3) in enumerate(val_loader):\n",
    "        data1, data2, data3 = data1.cuda(), data2.cuda(), data3.cuda()\n",
    "        embedded_a, embedded_p, embedded_n = model(data1), model(data2), model(data3)\n",
    "\n",
    "        dist_a = F.pairwise_distance(embedded_a, embedded_n, 2)\n",
    "        dist_b = F.pairwise_distance(embedded_a, embedded_p, 2)\n",
    "        diff = (dist_a - dist_b).cpu().data\n",
    "\n",
    "        pred = (diff > 0).int().tolist()\n",
    "        val_labels_pred += pred\n",
    "\n",
    "    f1 = f1_score(val_labels_pred, val_labels)\n",
    "    acc = accuracy_score(val_labels_pred, val_labels)\n",
    "    val_f1_score.append(f1)\n",
    "    print('Epoch :',e,' Current Validation F1 Score: ', f1, 'Current Val Acc:', acc)\n",
    "    \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## evaluation\n",
    "\n",
    "\n",
    "#Epoch : 2  Current Validation F1 Score:  0.734122353725621 Current Val Acc: 0.7320228494623656\n",
    "print(val_f1_score)\n",
    "#Epoch : 3  Current F1 Score:  0.8208248816768087\n",
    "# 0.5891517599538373"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(0, len(val_labels_pred)): \n",
    "    #val_labels_pred[i] = int(val_labels_pred[i]) \n",
    "#f1 = f1_score(val_labels_pred, val_labels)\n",
    "\n",
    "print(len(val_labels_pred,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = datatorch.DataLoader(dataset=test_dataset, shuffle = False, batch_size= 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.eval()\n",
    "for idx, (data1, data2, data3) in enumerate(test_loader):\n",
    "    data1, data2, data3 = data1.cuda(), data2.cuda(), data3.cuda()\n",
    "    embedded_a, embedded_p, embedded_n = model(data1), model(data2), model(data3)\n",
    "    dist_a = F.pairwise_distance(embedded_a, embedded_n, 2)\n",
    "    dist_b = F.pairwise_distance(embedded_a, embedded_p, 2)\n",
    "    diff = (dist_a - dist_b)\n",
    "    if diff[diff > 0.015].size()[0]!=0:\n",
    "        model.train()\n",
    "        target = torch.FloatTensor(dist_a[diff > 0.015].size()).fill_(1)\n",
    "        target = target.cuda()\n",
    "        rank_loss = criterion(dist_a[diff > 0.015],dist_b[diff > 0.015],target)\n",
    "        #loss_embedd = embedded_a.norm(2) + embedded_n.norm(2) + embedded_p.norm(2)\n",
    "        loss = rank_loss# + 0.001*loss_embedd\n",
    "        #loss = criterion(y_pred,label)\n",
    "        # call optimizer.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "        # run backward method\n",
    "        loss.backward()\n",
    "        # run optimizer step\n",
    "        optimizer.step()\n",
    "        model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_triplets_pred = []\n",
    "model.eval()\n",
    "for idx, (data1, data2, data3) in enumerate(test_loader):\n",
    "    data1, data2, data3 = data1.cuda(), data2.cuda(), data3.cuda()\n",
    "    embedded_a, embedded_p, embedded_n = model(data1), model(data2), model(data3)\n",
    "    dist_a = F.pairwise_distance(embedded_a, embedded_n, 2)\n",
    "    dist_b = F.pairwise_distance(embedded_a, embedded_p, 2)\n",
    "    diff = (dist_a - dist_b)\n",
    "    diff = diff.cpu().data\n",
    "    #print(diff[diff > 0.015], len(diff[diff > 0.15].size()))#embedded_a[np.abs(diff)>0.015,:])\n",
    "    pred = (diff > margin).int().tolist()\n",
    "    test_triplets_pred += pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_triplets_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submission4_Ketzel.txt', 'w') as f:\n",
    "    for item in test_triplets_pred:\n",
    "        f.write(str(item) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
