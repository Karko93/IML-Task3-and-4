{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv \n",
    "from UtilityFunctions import ReadData_int, WriteData, ReadData_char\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels, test_features = ReadData_char()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_columns(arr):\n",
    "    combined =np.apply_along_axis(lambda d: d[0]+d[1],1,arr)\n",
    "    print(combined.shape,arr.shape,np.unique(combined).shape)\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112000,) (112000, 2) (400,)\n",
      "(48000,) (48000, 2) (400,)\n"
     ]
    }
   ],
   "source": [
    "train_features = np.column_stack((train_features,combine_columns(train_features[:,0:2])))\n",
    "test_features = np.column_stack((test_features,combine_columns(test_features[:,0:2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ordinalEncoder = OrdinalEncoder(dtype= np.int64)\n",
    "ordinalEncoder.fit(train_features)\n",
    "train_enc = ordinalEncoder.transform(train_features)\n",
    "test_enc = ordinalEncoder.transform(test_features)\n",
    "\n",
    "one = OneHotEncoder()\n",
    "one.fit(train_enc)\n",
    "train_enc = one.transform(train_enc).toarray()\n",
    "test_enc = one.transform(test_enc).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_enc, train_labels, test_size= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler = StandardScaler()\n",
    "std_scaler.fit(X_train)\n",
    "X_train_trsf = std_scaler.transform(X_train)\n",
    "X_val_trsf = std_scaler.transform(X_val)\n",
    "X_test_trsf = std_scaler.transform(test_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuralNet(X,y):\n",
    "    mlpclass = MLPClassifier(hidden_layer_sizes=(100, 100), max_iter=120, verbose=10, solver='adam', alpha=0.0001, batch_size='auto')\n",
    "    mlpclass.fit(X,y)\n",
    "    \n",
    "    return mlpclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(model,X,y = None):\n",
    "    y_pred = model.predict(X)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.16432995\n",
      "Iteration 2, loss = 0.14173867\n",
      "Iteration 3, loss = 0.13930238\n",
      "Iteration 4, loss = 0.13774654\n",
      "Iteration 5, loss = 0.13565785\n",
      "Iteration 6, loss = 0.13415568\n",
      "Iteration 7, loss = 0.13173315\n",
      "Iteration 8, loss = 0.12963940\n",
      "Iteration 9, loss = 0.12788664\n",
      "Iteration 10, loss = 0.12553499\n",
      "Iteration 11, loss = 0.12321000\n",
      "Iteration 12, loss = 0.12065534\n",
      "Iteration 13, loss = 0.11730205\n",
      "Iteration 14, loss = 0.11429930\n",
      "Iteration 15, loss = 0.11070627\n",
      "Iteration 16, loss = 0.10773949\n",
      "Iteration 17, loss = 0.10427911\n",
      "Iteration 18, loss = 0.10179367\n",
      "Iteration 19, loss = 0.09888098\n",
      "Iteration 20, loss = 0.09626309\n",
      "Iteration 21, loss = 0.09387376\n",
      "Iteration 22, loss = 0.09248319\n",
      "Iteration 23, loss = 0.08978507\n",
      "Iteration 24, loss = 0.08846465\n",
      "Iteration 25, loss = 0.08725434\n",
      "Iteration 26, loss = 0.08550610\n",
      "Iteration 27, loss = 0.08500526\n",
      "Iteration 28, loss = 0.08411807\n",
      "Iteration 29, loss = 0.08296251\n",
      "Iteration 30, loss = 0.08214261\n",
      "Iteration 31, loss = 0.08126830\n",
      "Iteration 32, loss = 0.08105810\n",
      "Iteration 33, loss = 0.08052951\n",
      "Iteration 34, loss = 0.08003760\n",
      "Iteration 35, loss = 0.07901745\n",
      "Iteration 36, loss = 0.07823174\n",
      "Iteration 37, loss = 0.07789954\n",
      "Iteration 38, loss = 0.07721039\n",
      "Iteration 39, loss = 0.07673947\n",
      "Iteration 40, loss = 0.07643542\n",
      "Iteration 41, loss = 0.07633260\n",
      "Iteration 42, loss = 0.07588080\n",
      "Iteration 43, loss = 0.07527771\n",
      "Iteration 44, loss = 0.07568709\n",
      "Iteration 45, loss = 0.07504610\n",
      "Iteration 46, loss = 0.07499696\n",
      "Iteration 47, loss = 0.07393233\n",
      "Iteration 48, loss = 0.07414430\n",
      "Iteration 49, loss = 0.07355459\n",
      "Iteration 50, loss = 0.07385522\n",
      "Iteration 51, loss = 0.07339730\n",
      "Iteration 52, loss = 0.07299905\n",
      "Iteration 53, loss = 0.07241165\n",
      "Iteration 54, loss = 0.07222118\n",
      "Iteration 55, loss = 0.07213816\n",
      "Iteration 56, loss = 0.07180320\n",
      "Iteration 57, loss = 0.07170644\n",
      "Iteration 58, loss = 0.07045793\n",
      "Iteration 59, loss = 0.07152639\n",
      "Iteration 60, loss = 0.07057324\n",
      "Iteration 61, loss = 0.07031042\n",
      "Iteration 62, loss = 0.07045490\n",
      "Iteration 63, loss = 0.07005531\n",
      "Iteration 64, loss = 0.06995566\n",
      "Iteration 65, loss = 0.06994533\n",
      "Iteration 66, loss = 0.06938624\n",
      "Iteration 67, loss = 0.06963284\n",
      "Iteration 68, loss = 0.06917304\n",
      "Iteration 69, loss = 0.06871895\n",
      "Iteration 70, loss = 0.06964774\n",
      "Iteration 71, loss = 0.06837597\n",
      "Iteration 72, loss = 0.06800307\n",
      "Iteration 73, loss = 0.06852034\n",
      "Iteration 74, loss = 0.06840003\n",
      "Iteration 75, loss = 0.06772743\n",
      "Iteration 76, loss = 0.06734422\n",
      "Iteration 77, loss = 0.06808259\n",
      "Iteration 78, loss = 0.06818455\n",
      "Iteration 79, loss = 0.06705402\n",
      "Iteration 80, loss = 0.06744849\n",
      "Iteration 81, loss = 0.06734794\n",
      "Iteration 82, loss = 0.06690906\n",
      "Iteration 83, loss = 0.06674455\n",
      "Iteration 84, loss = 0.06661494\n",
      "Iteration 85, loss = 0.06632305\n",
      "Iteration 86, loss = 0.06677705\n",
      "Iteration 87, loss = 0.06553308\n",
      "Iteration 88, loss = 0.06581672\n",
      "Iteration 89, loss = 0.06557167\n",
      "Iteration 90, loss = 0.06564195\n",
      "Iteration 91, loss = 0.06537370\n",
      "Iteration 92, loss = 0.06539467\n",
      "Iteration 93, loss = 0.06547584\n",
      "Iteration 94, loss = 0.06550810\n",
      "Iteration 95, loss = 0.06458682\n",
      "Iteration 96, loss = 0.06399949\n",
      "Iteration 97, loss = 0.06436933\n",
      "Iteration 98, loss = 0.06412015\n",
      "Iteration 99, loss = 0.06452607\n",
      "Iteration 100, loss = 0.06425742\n",
      "Iteration 101, loss = 0.06433656\n",
      "Iteration 102, loss = 0.06437400\n",
      "Iteration 103, loss = 0.06395407\n",
      "Iteration 104, loss = 0.06365496\n",
      "Iteration 105, loss = 0.06366920\n",
      "Iteration 106, loss = 0.06285160\n",
      "Iteration 107, loss = 0.06331045\n",
      "Iteration 108, loss = 0.06307298\n",
      "Iteration 109, loss = 0.06318468\n",
      "Iteration 110, loss = 0.06293305\n",
      "Iteration 111, loss = 0.06249880\n",
      "Iteration 112, loss = 0.06263039\n",
      "Iteration 113, loss = 0.06336188\n",
      "Iteration 114, loss = 0.06221570\n",
      "Iteration 115, loss = 0.06224931\n",
      "Iteration 116, loss = 0.06255628\n",
      "Iteration 117, loss = 0.06185223\n",
      "Iteration 118, loss = 0.06190302\n",
      "Iteration 119, loss = 0.06178538\n",
      "Iteration 120, loss = 0.06203536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ketzel\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (120) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "mlp = neuralNet(X_train_trsf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score is 0.616039744499645\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = predict_class(mlp,X_val_trsf)\n",
    "print(\"F1-score is\", f1_score(y_val_pred,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = predict_class(mlp,X_test_trsf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we return the data to the csv file   \n",
    "filename = \"submission_Ketzel.csv\"\n",
    "  \n",
    "# writing to csv file \n",
    "with open(filename, 'w') as csvfile:\n",
    "    # creating a csv writer object \n",
    "    csvwriter = csv.writer(csvfile)    \n",
    "    # writing the data rows \n",
    "    csvwriter.writerows(output_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
